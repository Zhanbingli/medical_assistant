"""
æœç´¢æ¨¡å— - å®ç°å¤šè·¯å¬å›å’Œ Rerank åŠŸèƒ½
"""
import ollama
from sentence_transformers import CrossEncoder
from typing import List, Tuple, Dict, Any
import logging

from config import (
    LLM_MODEL,
    EMBEDDING_MODEL,
    RERANKER_MODEL,
    MULTI_QUERY_COUNT,
    RECALL_N_RESULTS,
    RERANK_TOP_K,
    RERANK_THRESHOLD,
    LLM_TEMPERATURE_CREATIVE,
    QUERY_EXPANSION_PROMPT
)
from database import MedicalKnowledgeDB

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class QueryExpander:
    """æŸ¥è¯¢æ‰©å±•å™¨ - ç”Ÿæˆç›¸å…³çš„åŒ»å­¦å…³é”®è¯"""

    def __init__(self, llm_model: str = LLM_MODEL):
        """
        åˆå§‹åŒ–æŸ¥è¯¢æ‰©å±•å™¨

        Args:
            llm_model: LLM æ¨¡å‹åç§°
        """
        self.llm_model = llm_model
        logger.info(f"æŸ¥è¯¢æ‰©å±•å™¨å·²åˆå§‹åŒ–: æ¨¡å‹={llm_model}")

    def expand(self, query: str, count: int = MULTI_QUERY_COUNT) -> List[str]:
        """
        æ‰©å±•æŸ¥è¯¢è¯ï¼Œç”Ÿæˆå¤šä¸ªç›¸å…³å…³é”®è¯

        Args:
            query: åŸå§‹æŸ¥è¯¢
            count: ç”Ÿæˆå…³é”®è¯æ•°é‡

        Returns:
            åŒ…å«åŸå§‹æŸ¥è¯¢å’Œæ‰©å±•æŸ¥è¯¢çš„åˆ—è¡¨
        """
        prompt = QUERY_EXPANSION_PROMPT.format(query=query, count=count)

        try:
            response = ollama.chat(
                model=self.llm_model,
                messages=[{'role': 'user', 'content': prompt}],
                options={'temperature': LLM_TEMPERATURE_CREATIVE}
            )

            queries = response['message']['content'].strip().split('\n')
            # æ¸…ç†åºå·å’Œç©ºç™½
            clean_queries = [
                q.split('.')[-1].strip()
                for q in queries
                if q.strip()
            ]

            # åŸå§‹æŸ¥è¯¢ + æ‰©å±•æŸ¥è¯¢
            result = [query] + clean_queries[:count]
            logger.info(f"æŸ¥è¯¢æ‰©å±•: {query} -> {result}")
            return result

        except Exception as e:
            logger.error(f"æŸ¥è¯¢æ‰©å±•å¤±è´¥: {e}")
            return [query]


class Reranker:
    """é‡æ’åºå™¨ - ä½¿ç”¨ CrossEncoder å¯¹æ£€ç´¢ç»“æœæ‰“åˆ†"""

    def __init__(self, model_name: str = RERANKER_MODEL):
        """
        åˆå§‹åŒ– Reranker

        Args:
            model_name: Reranker æ¨¡å‹åç§°
        """
        self.model_name = model_name
        logger.info(f"æ­£åœ¨åŠ è½½ Rerank æ¨¡å‹: {model_name}")
        self.model = CrossEncoder(model_name)
        logger.info("Rerank æ¨¡å‹åŠ è½½å®Œæˆ")

    def rerank(
        self,
        query: str,
        documents: List[str],
        metadatas: List[Dict[str, Any]]
    ) -> List[Tuple[str, float, Dict[str, Any]]]:
        """
        å¯¹æ–‡æ¡£è¿›è¡Œé‡æ’åº

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            documents: æ–‡æ¡£åˆ—è¡¨
            metadatas: å…ƒæ•°æ®åˆ—è¡¨

        Returns:
            (æ–‡æ¡£, åˆ†æ•°, å…ƒæ•°æ®) çš„åˆ—è¡¨ï¼ŒæŒ‰åˆ†æ•°é™åºæ’åˆ—
        """
        if not documents:
            return []

        # æ„é€ æŸ¥è¯¢-æ–‡æ¡£å¯¹
        pairs = [[query, doc] for doc in documents]

        # é¢„æµ‹åˆ†æ•°
        scores = self.model.predict(pairs)

        # ç»„åˆå¹¶æ’åº
        scored_docs = list(zip(documents, scores, metadatas))
        scored_docs.sort(key=lambda x: x[1], reverse=True)

        logger.debug(f"Rerank å®Œæˆ: {len(scored_docs)} æ¡ç»“æœ")
        return scored_docs


class MedicalSearchEngine:
    """åŒ»å­¦æœç´¢å¼•æ“ - æ•´åˆå¤šè·¯å¬å›å’Œ Rerank"""

    def __init__(
        self,
        db: MedicalKnowledgeDB,
        reranker: Reranker,
        expander: QueryExpander
    ):
        """
        åˆå§‹åŒ–æœç´¢å¼•æ“

        Args:
            db: æ•°æ®åº“å®ä¾‹
            reranker: é‡æ’åºå™¨å®ä¾‹
            expander: æŸ¥è¯¢æ‰©å±•å™¨å®ä¾‹
        """
        self.db = db
        self.reranker = reranker
        self.expander = expander
        logger.info("åŒ»å­¦æœç´¢å¼•æ“å·²åˆå§‹åŒ–")

    def _generate_embedding(self, text: str) -> List[float]:
        """ç”Ÿæˆæ–‡æœ¬åµŒå…¥å‘é‡"""
        try:
            response = ollama.embeddings(model=EMBEDDING_MODEL, prompt=text)
            return response['embedding']
        except Exception as e:
            logger.error(f"åµŒå…¥ç”Ÿæˆå¤±è´¥: {e}")
            return []

    def _multi_recall(
        self,
        queries: List[str]
    ) -> Tuple[List[str], List[Dict[str, Any]], List[str]]:
        """
        å¤šè·¯å¬å›ï¼šå¯¹å¤šä¸ªæŸ¥è¯¢åˆ†åˆ«æ£€ç´¢å¹¶å»é‡

        Args:
            queries: æŸ¥è¯¢åˆ—è¡¨

        Returns:
            (æ–‡æ¡£åˆ—è¡¨, å…ƒæ•°æ®åˆ—è¡¨, è°ƒè¯•æ—¥å¿—åˆ—è¡¨)
        """
        all_documents = []
        all_metadatas = []
        seen_docs = set()
        debug_logs = []

        for q in queries:
            try:
                # ç”ŸæˆåµŒå…¥
                embedding = self._generate_embedding(q)
                if not embedding:
                    continue

                # æ£€ç´¢
                results = self.db.query(embedding, n_results=RECALL_N_RESULTS)

                # æå–ç»“æœ
                if results['documents'] and results['documents'][0]:
                    docs = results['documents'][0]
                    # å®¹é”™å¤„ç†ï¼šå¦‚æœæ²¡æœ‰ metadataï¼Œå¡«å……ç©ºå­—å…¸
                    metas = results.get('metadatas', [[]])[0]
                    if not metas:
                        metas = [{}] * len(docs)

                    # å»é‡
                    for doc, meta in zip(docs, metas):
                        if doc not in seen_docs:
                            all_documents.append(doc)
                            all_metadatas.append(meta)
                            seen_docs.add(doc)

            except Exception as e:
                debug_logs.append(f"âš ï¸ æ£€ç´¢å…³é”®è¯ '{q}' æ—¶å‡ºé”™: {e}")

        return all_documents, all_metadatas, debug_logs

    def search(
        self,
        query: str,
        debug: bool = False
    ) -> Tuple[str, List[str]]:
        """
        æ‰§è¡Œå®Œæ•´çš„æœç´¢æµç¨‹ï¼šæŸ¥è¯¢æ‰©å±• -> å¤šè·¯å¬å› -> Rerank

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            debug: æ˜¯å¦è¿”å›è°ƒè¯•ä¿¡æ¯

        Returns:
            (æ£€ç´¢ç»“æœæ–‡æœ¬, è°ƒè¯•æ—¥å¿—åˆ—è¡¨)
        """
        debug_logs = []

        try:
            debug_logs.append(f"ğŸ” åŸå§‹æŸ¥è¯¢: {query}")

            # 1. æŸ¥è¯¢æ‰©å±•
            expanded_queries = self.expander.expand(query, count=MULTI_QUERY_COUNT)
            if debug:
                debug_logs.append(f"ğŸ§  æ‰©å±•å…³é”®è¯: {expanded_queries}")

            # 2. å¤šè·¯å¬å›
            all_documents, all_metadatas, recall_logs = self._multi_recall(expanded_queries)
            debug_logs.extend(recall_logs)

            if not all_documents:
                logger.info("æœªæ‰¾åˆ°ç›¸å…³èµ„æ–™")
                return "æœªæ‰¾åˆ°ç›¸å…³èµ„æ–™ã€‚", debug_logs

            debug_logs.append(f"âˆ‘ å…±å¬å› {len(all_documents)} æ¡ä¸é‡å¤ç‰‡æ®µï¼Œå¼€å§‹ Rerank...")

            # 3. Rerank é‡æ’åº
            scored_docs = self.reranker.rerank(query, all_documents, all_metadatas)

            # 4. ç­›é€‰é«˜è´¨é‡ç»“æœ
            top_k_docs = []

            for doc, score, meta in scored_docs:
                source_name = meta.get('source', 'æœªçŸ¥æ¥æº') if meta else 'æœªçŸ¥æ¥æº'

                # è®°å½•è¯¦ç»†æ—¥å¿—
                if debug:
                    preview = doc[:20].replace('\n', ' ')
                    log_str = f"[{score:.2f}] {source_name}: {preview}..."
                    debug_logs.append(log_str)

                # ç­›é€‰é€»è¾‘ï¼šé˜ˆå€¼è¿‡æ»¤ + Top-K
                if len(top_k_docs) < RERANK_TOP_K and score > RERANK_THRESHOLD:
                    doc_with_source = f"{doc}\n[æ¥æº: {source_name}]"
                    top_k_docs.append(doc_with_source)

            if not top_k_docs:
                logger.info("èµ„æ–™ç›¸å…³åº¦è¾ƒä½")
                return "èµ„æ–™ç›¸å…³åº¦è¾ƒä½ï¼Œå»ºè®®è¡¥å……ç»†èŠ‚ã€‚", debug_logs

            result_text = "\n---\n".join(top_k_docs)
            logger.info(f"æœç´¢å®Œæˆ: è¿”å› {len(top_k_docs)} æ¡é«˜è´¨é‡ç»“æœ")
            return result_text, debug_logs

        except Exception as e:
            error_msg = f"æ£€ç´¢è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {str(e)}"
            logger.error(error_msg)
            return error_msg, [str(e)]
